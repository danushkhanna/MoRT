import langchain
from langchain import models
from llama2 import LLama2
import streamlit as st
from streamlit_chat import message
import json
from langchain import Refine

# Initialize LangChain APIs
# langchain_api = langchain.API(models.LangChainModel)
# llama2_api = LLama2('YOUR_LLAMA2_API_KEY')

# Set up the LangChain client with an API key
client = langchain.Client(api_key="YOUR_API_KEY")

# Define the LLaMA 2 model architecture
model = langchain.models.LLaMA2(num_layers=12, hidden_size=768, num_heads=12)
model.load_pretrained_weights("llama-2")
refiner = Refine(client, model)

def get_text():
    ''' 
    Take in user input and display it onto the screen.
    
    This function creates a text input field, waits for the user to input some text, and stores the input. 
    Also, it displays the user input in the chat interface.

    Returns
    -------
    str
        User input.
    '''
    s = st.empty()
    uin = s.text_input("You: ")
    if uin == "":
        return ""
    st.session_state.past.append(uin)
    message(uin, is_user=True)
    s.empty()
    return uin

def generate_text(prompt):
    '''
    Generate a response based on user input prompt.

    This function is responsible for generating movie recommendations based on a given prompt. 
    It generates text based on the prompt and returns the top recommendation as a string.

    Parameters
    ----------
    str
        Prompt given by user.
    
    Returns
    -------
    str
        Top movie recommendation.
    '''
    # completions = langchain_api.completions(
    #     prompt=prompt,
    #     num_completions=1,
    #     max_length=200,
    #     freq_threshold=0.01,
    #     diversity_threshold=0.01,
    #     ignore_stopwords=True,
    #     tokenizer='wordpiece',
    #     temperature=0.7,
    #     topk=5,
    #     k=5,
    #     seed=42,
    # )
	
    # generated_text = completions['results'][0]['output']
    # fine_tuned_text = llama2_api.refine(generated_text, num_beams=5, beam_search_steps=5)
    
    tokenizer = model.tokenizer
    encoded_prompt = tokenizer.encode(prompt, return_tensors="pt")
    generated_response = model.generate(encoded_prompt, max_length=50, temperature=0.9, diversity=0.5)
    fine_tuned_text = refiner.refine(generated_response, num_iterations=3)

    return fine_tuned_text

def handle_recommendation(response):
    '''
    Display title, synopsis, image, trailer URL, and genre of a movie to user.

    This function displays movie recommendations to the user. 
    It takes the generated text as input, parses it, and displays the details of the recommended movie.

    Parameters
    ----------
    str
        Text generated by recommender.
    '''
    print(response)
    responses = json.loads(response[response.find('['):])
    for response in responses:
        st.image(response['image'])
        out = f"Title: {response['title']}\n\nSynopsis:\n{response['synopsis']}\n\nGenre(s): {response['genre']}\n\nWatch the trailer [here]({response['trailer']})!"
        print(out)
        st.session_state.generated.append(out)
        st.write(out)

def get_recommendation():
    ''' 
    Check user's most recent input and generate a response.
    
    This function is responsible for retrieving recommendations based on the user input. 
    It may be thought of as a middleman between the chat interface and the displaying of new recommendations.
    It retrieves the user's most recent input, retrieves recommendations based on that input, and gets it displayed.
    '''
    if len(st.session_state.past) == 0:
        return
    prompt = st.session_state.past[-1]
    handle_recommendation(generate_text(prompt))

def add_buttons():
    # if st.button("More like this"):
    #     handle_recommendation(generate_text("More like this"))
    # if st.button("Something else..."):
    #     handle_recommendation(generate_text("Something else"))
    pass

def init():
    '''
    Set up the chat interface, initialize session state variables, take in user input and get recommendation.

    It displays a welcome message and waits for the user to input some text. 
    It then initializes crucial session state variables. 
    Once user input is obtained, it calls the functions responsible for generating recommendations and displaying them.
    It then waits for the user to input more text.
    '''
    print("INIT")
    st.title("Mort")
    message("Hey there! What would you like to watch today?")
    if 'turn' not in st.session_state:
        st.session_state['turn'] = 'user'
    if 'generated' not in st.session_state:
        st.session_state['generated'] = []
        # st.session_state.generated.append("Hey there! What would you like to watch today?")
    if 'past' not in st.session_state:
        st.session_state['past'] = []
        get_text()
        return

    for i in range(len(st.session_state.generated)):
        message(st.session_state.past[i], is_user=True)
        message(st.session_state.generated[i])
    if get_text() != "":
        get_recommendation()
    add_buttons()

init()
